---
title: "Thesis_Overview"
author: "Vincent Wauters"
date: "27 February 2018"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r installing_packages}
#install.packages("enetLTS")
#install.packages("robustbase")
#install.packages("mvtnorm")
#install.packages("MASS") # confint
#install.packages("robust")
#install.packages("MatrixModels")
#install.packages("glmnet")
#install.packages("caret") # tuning alpha for glmnet2 in logit_sim
```

```{r loading_libraries}
library(enetLTS)
library(robustbase)
library(mvtnorm)
library(MASS)
library(robust)
library(MatrixModels)
library(glmnet)
library(caret)
```

Sourcing functions defined in separate .R files.
```{r sourcing_functions}
source(file = "C://Users/Vincent Wauters/Google Drive/Schoolwerk/KU Leuven/Thesis_Sparse_Robust_Logistic_Regression/binary_reg_dgp1.R")
source(file = "C://Users/Vincent Wauters/Google Drive/Schoolwerk/KU Leuven/Thesis_Sparse_Robust_Logistic_Regression/logit_sim.R")
source(file = "C://Users/Vincent Wauters/Google Drive/Schoolwerk/KU Leuven/Thesis_Sparse_Robust_Logistic_Regression/logit_loss.R")
```

To get a better grasp of the concepts of robust and sparse modelling some simple examples will be given that isolate single issues and apply it on a simple models.

# Linear Models
## Linear - Low Dimensional (LD)
### Linear - LD - No Outliers

__USING OLS__

In a first step data is generated without outliers. A simple data generating process (DGP) $y = \beta_0 + \beta_1 * x_1 + \varepsilon$ and the same model is estimated by OLS.
```{r data_and_ols_no_outliers}
## Creating data
# Setting sample size
n <- 500

# Setting Coviates (Simple fixed design)
x1 <- c(rep(x = 10, times = floor(n/2)), rep(x = 20, times = floor(n/2)))

# Setting beta0, beta1
beta0 <- 100
beta1 <- 10

# Defining error
e <- rnorm(n = n,
            mean = 0,
            sd = 5)

# Defining the outcome
y <- beta0 + beta1 * x1 + e

## Fitting OLS
lm1 <- lm(y ~ x1) # (Includes intercept)
summary(lm1)

## Plotting
plot(x = x1,
     y = y,
     main = "No outliers, OLS fit")
abline(lm1)
```

__USING LTS__

A robust estimator for the linear model, the __Least Trimmed Squares (LTS)__ estimator can also be used, and should give the same results. The function `ltsReg()` (capital R) from the `robustbase` can be used. The default $\alpha = 0.5$ this leads to a $h$ sample size of $h = $ __to do__
```{r LTS_linear_no_outliers}
# Fitting LTS
lts1 <- ltsReg(y ~ x1, alpha = 0.5) # Default
summary(lts1)

# Fitting LTS with less trimming
lts2 <- ltsReg(y ~ x1, alpha = 0.95) # Closer to OLS
summary(lts2)

## Plotting LTS
plot(x = x1,
     y = y,
     main = "Clean data: OLS vs. LTS")
abline(lts1, col = "black") # LTS Line
abline(lm1, col = "gray", lwd = 2, lty = 2)
legend("bottomright",
       legend = c("OLS", "LTS"),
       lty = 1:2,
       lwd = 1:2,
       col = c("black", "gray"))
```

__CONCLUSION: Yes in the linear low dimensional case, LTS seem to do equally good (visually at least) as OLS in clean case__

__TO DO: what's the relation between alpha and the error variance (scale) estimate?__
__TO DO: I have no idea why the degrees of freedom on the residuals is not $n - p?!__


### Linear - LD - Outliers
Let's now introduce some __leverage points__, these are points that are outlying in the X direction. There are __good leverage points__ which have outlying X values but have a y-value that corresponds to the value that would be taken on by the relation follows from the other points. __Bad leverage points__ have outlying X values and have a non-fitting y value. 

Bad leverage points will be introduced, set at the coordinate (30, 150 + $e$) with $e$ coming from a $N(0, \sigma = 5)$ distribution or just put otherwise $y \sim N(150, 5)$. This is certainly a bad leverage point because a predicted reasonable value for $x1 = 30$ would be around 400.
```{r bad_leverage_point}
# Take look at current dataset
plot(x = x1,
     y = y,
     main = "Outliers Visualization in Linear Models")
abline(a = coef(lm1)[1],
       b = coef(lm1)[2])

# Introducing leverage points
n_outlier1 <- 50 # Amount of outliers
n2 <- n1 + n_outlier1

# Making them bad outliers
outliers1 <- rnorm(mean = 150, sd = 5, n = n_outlier1)

x1 <- c(x1, rep(30, n_outlier1))
y <- c(y, outliers1)

# Plotting
plot(x = x1,
     y = y,
     main = "OLS fit on regular data, bad leverage points added to display")
abline(lm1)
```

When fitting a model to this model that has 50/550 leverage points using OLS but also the LTS estimator:
```{r bad_leverage_ols_lts}
# Fitting OLS
lm2 <- lm(y ~ x1)
summary(lm2)

# Fitting LTS
lts2 <- ltsReg(y ~ x1)
summary(lts2)

# Plotting
plot(x = x1, 
     y = y,
     main = "Impact of bad leverage points")
abline(lm1, col = "gray", lwd = 2) # OLS on regular data only
abline(lm2, col = "black") # OLS on all data
abline(lts2, col = "red") # LTS on all dat
legend("bottomleft",
       legend = c("OLS no outliers",
                  "OLS outliers",
                  "LTS outliers"),
       lty = 1,
       col = c("gray", "black", "red"))
# OLS on the non-outlying points versus LTS: same, good!

```

Let's take a quick look at the LTS regression results on this dirty data:
```{r bad_leverage_lts_detail}
summary(lts2)
coef(lts2)

# Real betas:
beta0; beta1

```

The LTS recovers the true parameter values.

## Linear - High Dimensional
### Linear - HD - No Outliers

Let's now make something that is a lot more high dimensional, something with p = 200 (with intercept: 201), but only 10 first betas are nonzero, and the sample size stays the same at 500, __this example is thus NOT n < p!__

```{r}
## Setting parameters
n1 # Keepign same sample size = 500
p_a <- 10 # True dimensionality
p_b <- 190 # Uninformative
p <- p_a + p_b # Total dimensionality

## Creating data
beta0 <- 1
beta <- c(beta0, rep(1, p_a), rep(0, p_b))

# Creating covariates
X <- rmvnorm(n = n1,
             mean = rep(0, p),
             sigma = diag(p))
# Adding intercept column
X <- cbind(rep(1, times = n1), X)

# Adding names
colnames(X) <- paste0("X", 0:p)
  
# Creating outcome
y <- X %*% beta + rmvnorm(n = n1,
                          mean = 0)

# Creating dataframe used for FITTING
data1 <- data.frame(cbind(y, X[, -1]))
names(data1)[1] <- "y" # Setting name of y (first col)

## Fitting
# Making formula
formula1 <- paste("y", paste0("X", 1:p, collapse = " + "), sep = " ~ ")

# OLS
lm3 <- lm(formula = formula1, data = data1)
summary(lm3)

# LTS
lts3 <- ltsReg(formula = formula1, data = data1)
```
__ TO DO: further check the lts3 problems__

# Logistic Regression
## Logistic - Low Dimensional
### Logistic - LD - No Outliers

If we want multiple runs of such model (i.e. simulation), we need to run it multiple times, now we will automate this using a very simple function (which we will not use much further on, I suppose) and then using `replicate()` on this function. The function will generate data and specify the DGP and fit a logit model, then get the coefficients. By replicating this many times, due to the slightly different data (X) every time being sampled __and__ also due to sampling from the binomial distribution (i.e. even with the exact same probability parameter we ofcourse get different realizations).

The function is very basic, the parameters cannot even be altered in this simple version, it's purely as an example now!
```{r temporary_logitcoefs_simulation_function}
## Very Simple logit simulation: coefficients
logitcoefs <- function() {
  # Sample size
  N <- 1000
  
  # Beta
  beta0 <- 1
  beta1 <- 2
  beta2 <- 3
  
  # Linear predictor (eta)
  x1 <- rnorm(N)
  x2 <- rnorm(N)
  eta <- beta0 + beta1 * x1 + beta2 * x2
  
  # Probability (pi or p) and outcome (0/1)
  p <- exp(eta)/(1 + exp(eta))
  y <- rbinom(n = N, size = 1, prob = p)
  
  # Data.frame
  df <- data.frame(y = y, x1 = x1, x2 = x2)
  
  # Fitting
  fit <- glm(y ~ x1 + x2, data = df, family = binomial(link = "logit"))
  
  # Returning coefs
  return(coef(fit))
}

# Replicating and getting results:
results <- t(replicate(n = 50, 
                       expr = logitcoefs())) # Transposing for more easy to read results
colMeans(results) # Averages per variable
# Comparing to original beta = 1, 2, 3 -> YES It's OK

```


__to do: recheck these:__
Running simulations: first set up all the wanted settings, then looping over all these settings. To facilitate this we will create a settings matrix called `settings`.
```{r}
# Defining all simulation settings
beta_vector <- c(1, 2, 3) # True betas, same for all
n <- 500 # Sample size
runs <- 199
dirty <- 0
#types <- c("glm", "glmrob")
types <- "enetLTS"

# Putting in matrix
settings <- expand.grid(n = n, runs = runs, dirty = dirty, type = types)
settings
```

And each time gather all the settings by keeping the names the same every time and assesing row by row. Thus we are looping over the settings:
```{r simulation_loop_over_settings}
# Making model list of length = amount of rows of settings
model_list <- vector("list", nrow(settings))

# Looping over the settings:
for(i in 1:nrow(settings)){
  
  # To get an idea of progression
  print(paste("iteration", i))
  
  # Extracting current row of settings
  current_settings <- settings[i, ]
  
  # Saving all seperate settings in different variables
  n <- current_settings$n
  runs <- current_settings$runs
  dirty <- current_settings$dirty
  type <- current_settings$type

  # Running models
  model_list[[i]] <- logit_sim(beta_vector = beta_vector,
                               n = n,
                               runs = runs,
                               dirty = dirty,
                               type = type)
  
}
```

__to do: maybe add somekind of fields that contain the simulation settings__

Let us quickly define a simulation summary function that returns:

* The true coefficients, as set by the user
* The estimated means of the coefficients (mean over simulations)
* 
```{r sim_summary_function}
# Summary of simulation function:
sim_summary <- function(sim_object, beta_vector){
  coefs <- t(sapply(sim_object, coef))
  true <- beta_vector
  mean <- colMeans(coefs)
  bias <- colMeans(coefs - beta_vector)
  mse <- colMeans((coefs - beta_vector)^2)
  
  results <- rbind(true, mean, bias, mse)
  return(results)
}
```

And check the results
```{r}
lapply(model_list, sim_summary, beta_vector)
```


### Logistic - LD - With Outliers
Let's try a very trivial __clean data__ setup, which does not actually allows me directly to see what the true $\beta$ is but gives some insights, far from ideal. We will take an increasing predictor $x_i = 1, 2, 3, ..., 100$ and an associated outcome $y_i = 0, ... 0, 1, ..., 1$, i.e. 0 for the first $2n/5$ (40%) and 1 for the last $2n/5$ (40%) observations, __for the middle we need some overlap in the observations to not have perfect separation__. To do this the middle $n/5$ (20%) variables are generated according to a Bernouilli distribution with $p = 0.5$.

```{r logit_manual_ld}
# Setting amount of obs:
n <- 200

# Predictors
X <- 1:n
  
# Outcome
set.seed(1234)
y <- c(rep(0, ((2/5) * n)), # 40 pct 0, 40pct 1, 20 pct: rbinom 50/50 in the middle to get OVERLAP
       rbinom(n = n/5, size = 1, prob = 0.50),
       rep(1, (2/5) * n))

# Data.frame:
data <- data.frame(y = y,
                   X = X)

# Plotting
plot(x = X,
     y = y,
     main = "Visualizing binary data")
```

Only clean data:
```{r plotting_logit}
# Fitting logit
logit1 <- glm(y ~ X, 
              family = binomial(link = "logit"),
              data = data)
logit1

# Getting predictions to plot:
logit1_preds_prob <- predict(logit1, type = "response")
logit1_preds_class <- ifelse(test = logit1_preds_prob > 0.5, yes = 1, no = 0)

# Plotting
plot(x = X,
     y = y,
     main = "Unidimensional Logit - No Outliers")
abline(h = 0.5, lty = 2)
lines(x = X,
      y = logit1_preds_prob)
points(x = X, 
       y = logit1_preds_class,
       pch = 2,
       col = "red")
legend("bottomright",
       legend = c("True Outcome",
                  "Class Prediction"),
       pch = 1:2,
       col = 1:2)
```

Now let's add leverage points to the example above somehow. We see that for X-values above (ca.) 100 the predictions are all 1, while those for X-values below 100 are 0. So let's try to add some 0-outcomes for those X-values above 200 (max of range of clean data), this will be very atypical, a leverage point. We will do this for the last 10 points of data (X = 190, ..., X = 200)
```{r plotting_logit_leverage}
# Setting y = 0 where it should be 1
data_dirty <- data # Copy
data_dirty[190:200, 1] <- 0 # Contaminate
data_dirty[190:200, 2] <- 290:300 # More leverage


# Fitting on dirty data
logit2 <- glm(y ~ X, 
              family = binomial(link = "logit"),
              data = data_dirty)
summary(logit2)

# Predictions
logit2_preds_prob <- predict(logit2, type = "response")
logit2_preds_class <- ifelse(test = logit2_preds_prob > 0.5, yes = 1, no = 0)

# Plotting
plot(x = data_dirty$X,
     y = data_dirty$y,
     main = "Unidimensional Logit - WITH Leverage Points",
     xlab = "X",
     ylab = "y")
lines(x = data_dirty$X,
      y = logit2_preds_prob)
points(x = X,
       y = logit2_preds_class,
       pch = 2,
       col = "red")
legend("topleft",
       legend = c("True Outcome",
                  "Class Prediction"),
       pch = 1:2,
       col = 1:2)

# Comparing coefs clean vs. dirty
coef(logit1)
coef(logit2)
```

Seeing how leverage points influence the fitted logit model and the related coefficients, the impact is obviously huge. However we actually not really know what the true value of the betas should be here due to our very simplistic setup!

Hence let's assume the following setup: we assume a Bernouilli distributed outcome, parametrized by the probability parmaeter $p$, and this $p = f(X, \beta)$, i.e. is some function of a structural component parametrized by $X$ and $\beta$. (See also: https://stats.stackexchange.com/questions/127226/logistic-regression-simulation-in-order-to-show-that-intercept-is-biased-when-y)

First, let us remind ourselves of the __logistic__ transformation (function), which is not the __logit__ transformation (it is the inverse logit). Let's present the logistic function in two equivalent forms:
$$f(x) = \frac{e^x}{1+e^x} = \frac{1}{1 + e^{-x}}$$

While the logit function is the inverse of this function and is in very general notation equal to:
$$f(x) = log(\frac{x}{1 - x})$$

Also note we can write the odds as the exponential taken of the log odds, as it is a 0-operation:

$$odds = \exp(log(odds))$$
Then see one can write the probability of the event $p$ (sometimes denotes as $\pi$) as (note we now start going from $x$ to $p$ to get a bit less general and more into the logit framework/language)

$$p = \frac{odds}{1 + odds}$$
To see why, remember that $odds = \frac{p}{1-p}$ so rewriting the above statement leads to the following, they should be equivalent (i.e. $p = p$) if the above statement is true

$$p = \frac{p/(1-p)}{1 + p/(1-p)} $$
$$p = \frac{p/(1-p)}{[(1-p)/(1-p)] + [p/(1-p)]} = \frac{p/(1-p)}{(1 - p + p)/(1-p)} = \frac{p/(1-p)}{1/(1-p)} = \frac{p (1-p)}{1 - p} = p$$
So indeed we have established that $p = \frac{odds}{1 + odds}$

Why is this useful? Because we also know that

$$log(odds) = \boldsymbol{X \beta}$$

In other words: the logit model is linear in terms of log-odds.
```{r logit_ld_alternative_dgp}
# Defining log-odds to probability function
lo2p = function(lo){
  odds = exp(lo)        
  p    = odds / (1 + odds)
  return(p)
}

# Setting DGP parameters
n <- 1000  # 1000 obs
beta0 <- 0.25 # intercept
beta1 <- 1 # slope
r <- 200 # amount of simulations

# Generating data
X <- rnorm(n) # Standard normal covariate
lo <- beta0 + beta1 * X # log-odds
p <- lo2p(lo) # Parameter vector of the Bernouilli
y <- rbinom(n = n, size = 1, prob = p) # 0/1 outcomes parametrized by p

# Also Ordering the data according to increasing X, makes life easier
idX <- order(X) # Indices, yes do this in 2 steps, otherwise messy!

X <- X[idX]
y <- y[idX]

# Running a single logit
logit3 <- glm(y ~ X,
              family = binomial(link = "logit"))

# Getting predictions to plot:
logit3_preds_prob <- predict(logit3, type = "response")
logit3_preds_class <- ifelse(test = logit3_preds_prob > 0.5, yes = 1, no = 0)



## Plotting
# True points
plot(x = X,
     y = y)
# Logit line
lines(x = X,
      y = logit3_preds_prob)

# Predicted points
points(x = X,
       y = logit3_preds_class,
       pch = 2,
       col = "red")
# Legend
legend("bottomright",
       legend = c("True Outcome",
                  "Class Prediction"),
       pch = 1:2,
       col = 1:2)

# These will store the estimation results
beta_hat0 <- numeric(r)  
beta_hat1 <- numeric(r)
y1_prop <- numeric(r) # Proportion of y = 1 in generated samples

# Running simulation (note: only y is random now, X fixed over samples)
for(i in 1:r){
  y <- rbinom(n = n, size = 1, prob = p)
  model <- glm(y ~ X, family = binomial(link = "logit"))
  beta_hat0[i] <- coef(model)[1]
  beta_hat1[i] <- coef(model)[2]
  y1_prop[i] <- mean(y)
}

## Results (over all simulation runs)
# Beta0
mean(beta_hat0)  
sd(beta_hat0)

# Beta1
mean(beta_hat1)
sd(beta_hat1)

# Proportion y = 1
mean(y1_prop) # Slightly unbalanced at beta0 = 0.25, beta1 = 1
```

Let's add some outliers now to the alternate DGP we had before. Therefore we take the last e.g. 50 points of the ordered X-values, make them a tad bigger (e.g. 5) and make the corresponding y-values 0 instead of 1.
```{r logit_alternative_contamination}
## Single logit
# Contamination
X_dirty <- X
X_dirty[950:1000] <- 5 + rnorm(n = length(X_dirty[950:1000]), mean = 0, sd = 1)

y_dirty <- y
y_dirty[950:1000] <- 0

# Also Ordering the data according to increasing X, makes life easier
idX <- order(X_dirty) # Indices, yes do this in 2 steps, otherwise messy!

X_dirty <- X_dirty[idX]
y_dirty <- y_dirty[idX]

# Fitting
logit4 <- glm(y_dirty ~ X_dirty,
              family = binomial(link = "logit"))
coef(logit4) ; coef(logit3) # The contaminated one is completely off

# Predicting
logit4_preds_prob <- predict(logit4, type = "response")
logit4_preds_class <- ifelse(test = logit4_preds_prob > 0.5, yes = 1, no = 0)

## Plotting
# True points
plot(x = X_dirty,
     y = y_dirty,
     xlim = c(-3, 5.1),
     main = "Comparison of logit on clean data versus contaminated data")
# Logit line (Clean only)
lines(x = X,
      y = logit3_preds_prob,
      lty = 2,
      col = "gray")
# Logit line (contaminated data)
lines(x = X_dirty,
      y = logit4_preds_prob)
# Predicted Classes (On dirty)
points(x = X,
       y = logit4_preds_class,
       pch = 2,
       col = "red")
# Legend
legend("topright",
       legend = c("True Outcome",
                  "Class Prediction"),
       pch = 1:2,
       col = 1:2)
legend("topleft",
       legend = c("Logit: All data",
                  "Logit: Clean data only"),
       lty = 1:2,
       col = c("black", "gray"))

```

## Logistic - High Dimensional
### Logistic - HD - No Outliers

Now that we have the data generating process function and plotting is not doable anymore due to the multiple dimensions. Hence we will not split up the outlying/non-outlying cases in different titles. So we simply use the DGP functions from before, set the dimensionality to be higher, amount of contamination to 0 and run some fitting functions such as `glm()` and `glmnet()` and `enetLTS()`.

```{r}
# Creating training set (clean in this first case)
train1 <- binary_reg_dgp2(n = 100,
                          p = 50,
                          p_a = 5,
                          beta = c(rep(1, 5), rep(0, 45)),
                          dirty = 0,
                          type = "bernoulli")

# Creating a test set (ALWAYS clean data!)
test1 <- binary_reg_dgp2(n = 100,
                          p = 50,
                          p_a = 5,
                          beta = c(rep(1, 5), rep(0, 45)),
                          dirty = 0,
                          type = "bernoulli")
# Ordinary logit
logit5 <- glm(y ~ ., 
              family = binomial(link = "logit"),
              control = glm.control(maxit = 200),
              data = train1)

# Coefficients
coef(logit5)

# Predictions
logit5_preds_prob <- predict(logit5,
                             newx = test1_X,
                             type = "response")
logit5_loss <- logit_loss(y_true = test1_y,
                          prob_hat = logit5_preds_prob)

### GLMNET
# Converting data
train1_X <- data.matrix(train1)[, -1]
train1_y <- data.matrix(train1)[, 1]

test1_X <- data.matrix(test1)[, -1]
test1_y <- data.matrix(test1)[, 1]

## LASSO logit (glmnet: alpha = 1)
lasso_logit1 <- cv.glmnet(x = train1_X,
                          y = train1_y,
                          family = "binomial",
                          alpha = 1,
                          type.measure = "deviance")
# Coefficients
coef(lasso_logit1, s = "lambda.min") # Absolute minimum lambda attained over CV
coef(lasso_logit1, s = "lambda.1se") # 1SE rule (more spare models)

# Predictions
lasso_logit1_preds_prob <- predict(lasso_logit1, 
                                   newx = test1_X,
                                   type = "response",
                                   s = "lambda.min")
# Loss
lasso_logit1_loss <- logit_loss(y_true = test1_y,
           prob_hat = lasso_logit1_preds_prob)


## Ridge logit (glmnet: alpha = 0)
ridge_logit1 <- cv.glmnet(x = train1_X,
                          y = train1_y,
                          family = "binomial",
                          alpha = 0,
                          type.measure = "deviance")
# Coefficients
coef(ridge_logit1, s = "lambda.min")
coef(ridge_logit1, s = "lambda.1se")

# Predictions
ridge_logit1_preds_prob <- predict(ridge_logit1, 
                                   newx = test1_X,
                                   type = "response",
                                   s = "lambda.min")
# Loss
ridge_logit1_loss <- logit_loss(y_true = test1_y,
                    prob_hat = ridge_logit1_preds_prob)

## Elastic Net logit (e.g. alpha = 0.75)
enet_logit1 <- cv.glmnet(x = train1_X,
                         y = train1_y,
                         family = "binomial",
                         alpha = 0.75,
                         type.measure = "deviance")
# Coefficients
coef(enet_logit1, s = "lambda.min")
coef(enet_logit1, s = "lambda.1se")

# Predictions
enet_logit1_preds_prob <- predict(enet_logit1,
                                  newx = test1_X,
                                  type = "response",
                                  s = "lambda.min")
# Loss
enet_logit1_loss <- logit_loss(y_true = test1_y,
                               prob_hat = enet_logit1_preds_prob)

### enetLTS
enetLTS_logit1 <- enetLTS(xx = train1[, -1],
                    yy = train1[, 1],
                    family = "binomial")

# Predictions
enetLTS_logit1_preds_prob <- predict(enetLTS_logit1, 
                                     newX = test1_X,
                                     vers = "reweighted",
                                     type = "response")
enetLTS_logit1_preds_prob <- unlist(unname(enetLTS_logit1_preds_prob))

# Loss
enetLTS_logit1_loss <- logit_loss(y_true = test1_y,
                                  prob_hat = enetLTS_logit1_preds_prob)


## Plotting losses in boxplot
# Combining losses in matrix
loss_comparison1 <- cbind(logit5_loss$loss, ridge_logit1_loss$loss, lasso_logit1_loss$loss, enet_logit1_loss$loss, enetLTS_logit1_loss$loss)
colnames(loss_comparison1) <- c("logit", "lasso", "ridge", "a .75", "enetLTS") # Giving column names

# Plotting
boxplot(loss_comparison1, 
        main = "Comparison of average loss on some Elastic Net Models")

# Plotting (zoomed in)
boxplot(loss_comparison1,
        main = "Comparison of average loss on some Elastic Net Models",
        ylim = c(0, 1))

# Other view: checking means of losses
loss_mean_comparison2 <- cbind(logit5_loss$avg_loss, lasso_logit1_loss$avg_loss, ridge_logit1_loss$avg_loss, enet_logit1_loss$avg_loss, enetLTS_logit1_loss$avg_loss)
colnames(loss_mean_comparison2) <- c("logit", "lasso", "ridge", "a .75", "enetLTS")

loss_mean_comparison2
```

So we see the models are very comparable in terms of loss, but ofcourse no outliers are introduced yet here!

__TO DO: maybe cv.glmnet tuned for alpha as well (manually)__

### Logistic - HD - With Outliers 

We will first create a training set (with contaminated data) and a clean dataset (same DGP, but setting dirty = 0). Then we run enetLTS using the first column of the training set as the outcome (`yy`) and all the other columns as the covariates (`xx`).

```{r logit_HD_dirty_fitting}
# Creating a training set
train1_dirty <- binary_reg_dgp2(n = 100,
                                p = 50,
                                p_a = 5,
                                beta = c(rep(1, 5), rep(0, 45)),
                                dirty = 0.1,
                                type = "bernoulli")
train1_dirty_X <- data.matrix(train1_dirty[, -1])
train1_dirty_y <- data.matrix(train1_dirty[, 1])

# Test set (just take one from before: HAS TO BE CLEAN!!!)

## logit (ordinary)
logit6 <- glm(y ~ .,
              family = binomial(link = "logit"),
              control = glm.control(maxit = 200),
              data = train1_dirty)

# Predictions
logit6_preds_prob <- predict(logit6,
                             newdata = data.frame(test1_X),
                             type = "response")
# Loss
logit6_loss <- logit_loss(y_true = test1_y,
                          prob_hat = logit6_preds_prob)

### glmnet
## LASSO
lasso_logit2 <- cv.glmnet(x = train1_dirty_X,
                          y = train1_dirty_y,
                          family = "binomial",
                          alpha = 1,
                          type.measure = "deviance")

# Predictions
lasso_logit2_preds_prob <- predict(lasso_logit2,
                                   newx = test1_X,
                                   type = "response",
                                   s = "lambda.min")
# Loss
lasso_logit2_loss <- logit_loss(y_true = test1_y,
                                prob_hat = lasso_logit2_preds_prob)



## Ridge
ridge_logit2 <- cv.glmnet(x = train1_dirty_X,
                          y = train1_dirty_y,
                          family = "binomial",
                          alpha = 0,
                          type.measure = "deviance")

# Predictions
ridge_logit2_preds_prob <- predict(ridge_logit2,
                                   newx = test1_X,
                                   type = "response",
                                   s = "lambda.min")
# Loss
ridge_logit2_loss <- logit_loss(y_true = test1_y,
                                prob_hat = ridge_logit2_preds_prob)

## Elastic net: Alpha = 0.75
enet_logit2 <- cv.glmnet(x = train1_dirty_X,
                         y = train1_dirty_y,
                         family = "binomial",
                         alpha = 0.75,
                         type.measure = "deviance")

# Predictions
enet_logit2_preds_prob <- predict(enet_logit2,
                                  newx = test1_X,
                                  type = "response",
                                  s = "lambda.min")
# Loss
enet_logit2_loss <- logit_loss(y_true = test1_y,
                               prob_hat = enet_logit2_preds_prob)



## DEFAULT enetLTS
enetLTS_logit2 <- enetLTS(xx = train1_dirty[, -1],
                    yy = train1_dirty[, 1],
                    family = "binomial")

# Predictions
enetLTS_logit2_preds_prob <- unlist(unname(predict(enetLTS_logit2,
                                                   newX = test1_X,
                                                   type = "response",
                                                   version = "reweighted")))

# Loss
enetLTS_logit2_loss <- logit_loss(y_true = test1_y,
                                  prob_hat = enetLTS_logit2_preds_prob)

## Plotting losses
loss_comparison2 <- cbind(logit6_loss$loss, lasso_logit2_loss$loss, ridge_logit2_loss$loss, enet_logit2_loss$loss, enetLTS_logit2_loss$loss)
colnames(loss_comparison2) <- c("logit", "lasso", "ridge", "a .75", "enetLTS")

# Plot
boxplot(loss_comparison2)


# Plot zoomed-in
boxplot(loss_comparison2,
        ylim = c(0, 1))

# Comparison with clean data and dirty data together
loss_comparison3 <- cbind(loss_comparison1, loss_comparison2)
boxplot(loss_comparison3)
boxplot(loss_comparison3, ylim = c(0, 1))

# Not always a good view: checking means of loss
loss_mean_comparison3 <- cbind(logit6_loss$avg_loss, lasso_logit2_loss$avg_loss, ridge_logit2_loss$avg_loss, enet_logit2_loss$avg_loss, enetLTS_logit2_loss$avg_loss)
colnames(loss_mean_comparison3) <- c("logit", "lasso", "ridge", "a .75", "enetLTS")

loss_mean_comparison3


# enetLTS: User supplied alpha/lambdas
enetLTS2 <- enetLTS(xx = train1_dirty[, -1],
                    yy = train1_dirty[, 1],
                    family = "binomial",
                    intercept = TRUE, # Default: TRUE
                    nfold = 5, # Default: 5
                    repl = 3, # Default: 5
                    alpha = c(seq(0, 1, 0.05)),
                    lambdas = c(2e-5, 2e-4, 2e-3, 2e-2, 2e-1, 2e0, 3, 4, 5))
enetLTS2

# enetLTS3: User supplied amount of alpha/lambdas
enetLTS3 <- enetLTS(xx = train1_dirty[, -1],
                    yy = train1_dirty[, 1],
                    family = "binomial",
                    intercept = TRUE, # Default: TRUE
                    nfold = 2, # Default: 5
                    repl = 2, # Default: 5
                    alpha = seq(0, 1, length = 20),
                    lambdas = seq(0, 4, length =  40))
enetLTS3
```

What about the trivial Most Frequent Class (MFC) classifier. However, this classifier does not produce predicted probabilities, just classes, hence the cross entropy loss cannot be calculated. But the misclassification loss (0-1) loss can be calculated ofcourse.

# Simulation Study

Let's manually try some simulations:
```{r}
# Parameters
p_a <- 5
p_b <- 45
beta <- c(rep(1, times = p_a), rep(0, times = p_b))
p <- length(beta)
runs <- 200
seed <- 596442 # KU Leuven student nr.
n <- 1000

### Running simulations
## Clean
# Ordinary (glm) logit
sim_glm1 <- logit_sim(beta = beta, 
                  p = p,
                  p_a = p_a,
                  n = n,
                  runs = runs,
                  dirty = 0,
                  dgp = "bernoulli",
                  type = "glm",
                  seed = seed)

# LASSO
sim_lasso1 <- logit_sim(beta = beta, 
                         p = p,
                         p_a = p_a,
                         n = n,
                         runs = runs,
                         dirty = 0,
                         dgp = "bernoulli",
                         type = "glmnet1",
                         seed = seed)

# glmrob
sim_glmrob1 <- logit_sim(beta = beta, 
                         p = p,
                         p_a = p_a,
                         n = n,
                         runs = runs,
                         dirty = 0,
                         dgp = "bernoulli",
                         type = "glmrob",
                         seed = seed)
# enetLTS
sim_enetLTS1 <- logit_sim(beta = beta, 
                         p = p,
                         p_a = p_a,
                         n = n,
                         runs = runs,
                         dirty = 0,
                         dgp = "bernoulli",
                         type = "enetLTS",
                         seed = seed)

## Dirty
# Ordinary (glm) logit
sim_glm1 <- logit_sim(beta = beta, 
                  p = p,
                  p_a = p_a,
                  n = n,
                  runs = runs,
                  dirty = 0.05,
                  dgp = "bernoulli",
                  type = "glm",
                  seed = seed)

```

Automating it using lapply:
```{r}
# Parameters
p_a <- 5
p_b <- 45
beta <- c(rep(1, times = p_a), rep(0, times = p_b))
p <- length(beta)
seed <- 596442 # KU Leuven student nr.
n <- 1000
dirty <- 0.05


# Running simulation oevr different fitting types
types <- c("glm", "glmnet1", "enetLTS")
runs <- 10
sim1 <- lapply(types, FUN = function(x) logit_sim(beta = beta, 
                         p = p,
                         p_a = p_a,
                         n = n,
                         runs = runs,
                         dirty = dirty,
                         dgp = "bernoulli",
                         type = x,
                         seed = seed))
names(sim1) <- c("glm", "glmnet", "enetLTS")

# Creating Summary
sim1_summary <- logit_sim_summary(sim1)

# Checking structure (names) of the sim1_summary
names(sim1_summary)

# Plotting some quantities
boxplot(sim1_summary$loss, main = "Test Loss")
boxplot(sim1_summary$misclass, main = "Misclassification Loss")
boxplot(sim1_summary$fpr, main = "Coefficient False Positive Rate")
boxplot(sim1_summary$tpr, main = "Coefficient True Positive Rate")
boxplot(sim1_summary$prec, main = "Coefficient Avg. RMSE")

  
  
# Using some other types (e.g. 2 glms)
types <- c("glm", "glm")
runs <- 10
sim2 <- lapply(types, FUN = function(x) logit_sim(beta = beta, 
                         p = p,
                         p_a = p_a,
                         n = n,
                         runs = runs,
                         dirty = dirty,
                         dgp = "bernoulli",
                         type = x,
                         seed = seed))
names(sim2) <- c("glm1", "glm2")
sim2_summary <- logit_sim_summary(sim2)
boxplot(sim2_summary$loss)
# Note that this will give exactly the same results because the seed is initialized each time!
```

Checking the results in terms of loss.
```{r}
sapply(lapply(1:runs, FUN = function(x) sim1[["x"]]$loss$avg_loss))

sim1[["glm"]]

# Loss
run_avg_loss <- data.frame(matrix(NA, nrow = runs, ncol = length(types)))
names(run_avg_loss) <- types
for(j in types){
  for(i in 1:runs){
    run_avg_loss[i, which(types == j)] <- sim1[[j]]$loss[[i]]$avg_loss
  }
}

boxplot(run_avg_loss)

# Misclass Loss
run_avg_misclass <- data.frame(matrix(NA, nrow = runs, ncol = length(types)))
names(run_avg_misclass) <- types
for(j in types){
  for(i in 1:runs){
    run_avg_misclass[i, which(types == j)] <- mean(sim1[[j]]$misclass[[i]])
  }
}

boxplot(run_avg_misclass)

```

We see a smaller difference in the (crossentropy) loss than in the misclassification one. Is there class imbalance maybe? This will be checked by printing the frequency tables of each test and training set associated with a run.

```{r Checking class imbalance}
# Training sets
for(j in types){
  for(i in 1:runs){
   print(table(sim1[[j]]$train[[i]]$y))
  }
}
# Looks rather balanced (40/60 ish)

# Test sets
for(j in types){
  for(i in 1:runs){
   print(table(sim1[[j]]$test[[i]]$y))
  }
}
# Balanced as well (40/60 ish)
```

No, this is not the case, it's fairly balanced!

Now, next up we need to define somekind of hit rate on the coefficients. Let's first start by exploring the structure of a single fit of e.g. glm or so. E.g. from logit6, which was fitted using the same beta as in sim1.
```{r}
# Getting true and fitted betas
beta_temp <- c(1, beta) # including intercept
logit6_coefs <- unname(coef(logit6))

# Getting nonzeros (T/F logical vector)
beta_temp_nonzero <- beta_temp != 0
logit6_nonzero <- logit6_coefs != 0

beta_temp_nonzero
logit6_nonzero 

# Checking equality (TRUE if both nonzero OR both zero)
beta_temp_nonzero == logit6_nonzero

# TPR: Seeing if it can retrieve all nonzeros correct: this means looking into first p_a+1 elements of fitted
mean(logit6_coefs[1:(p_a + 1)] != 0) # TRUE POSITIVE RATE == 100%

## FPR: the amount of beta_hats that are different from 0 but the true beta is 0, divided by amount of true ZEROs
# True zeros: p_b (denominator)
p_b

# fitted betas that are nonzero while the true betas are 0
logit6_coefs[(p_a + 1):p+1] != 0
# counting by taking SUM
sum(logit6_coefs[(p_a + 1):p+1] != 0)

# Dividing to get FPR
sum(logit6_coefs[(p_a + 1):p+1] != 0) / p_b # FPR = 100% (BAD!)

## FNR: when fitted is zero and true fitted is nonzero divided by amount of true nonzero
# true nonzero: p_a+1 (p_a plus intecept): denominator
p_a + 1
 
# numerator: amount of fitted coefs that is 0 while true beta !=0
logit6_coefs[1:(p_a+1)] == 0
# getting amount by taking sum (not length!)
sum(logit6_coefs[1:(p_a+1)] == 0)

# Dividing to get FNR
sum(logit6_coefs[1:(p_a+1)] == 0) / (p_a + 1) # FNR = 0 (GOOD, but not really eye opening here)

## Precisision
sqrt(sum(logit6_coefs - c(1, beta))^2/(length(logit6_coefs)))

```
Need to keep the beta including and excluding zero into account.

This is all a big mess, so we have defined a function that summarizes everything `logit_sim_summary()`:
```{r}
logit_sim_summary(sim2)
```




# How to do AIC/BIC selection

So I was screwing around a lot on how to do the AIC/BIC selection, so probably I'll just fit somekind of model setting nfold = 1, repl = 1 and set alphas and lambdas myself.

So in any case: let's remember why someone should use AIC/BIC etc for model selection. Basically it also (up to some constants) also asymptotically estimates the (generalizaion) loss. To do this we just take the training loglikelihood. We have given: the loss which is the negative loglikelihood. So we can just do $\times -1$. So we can use this to choose the ideal setting of lambda. Let's see manually, e.g. with enetLTS. Suppose now we fit the model using a user-set alpha and lambda, force the cross validation to 1 fold and 1 replication (basically turning CV off). But; this doesn't seem to work, because the loss (or loglik) from a model with contamination would be infinity.

There is somekind of a paradox here (or just something to keep in mind very carefully): keeping in mind real-world applications. Splitting the dataset at hand to select a model etc. or to get performance measures, is good. But we cannot assume we have an outlier-free dataset at hand, so it will be difficult to tune with that.

What about taking median versua mean (it's more robust) of loglik...

```{r}
# Fitting
enetLTS_logit3 <- enetLTS(xx = train1_dirty_X,
                    yy = train1_dirty_y,
                    family = "binomial",
                    lambdas = 0.01,
                    alphas = 0.8)

enetLTS_logit3b <- enetLTS(xx = train1_dirty_X,
                    yy = train1_dirty_y,
                    family = "binomial",
                    lambdas = 2e-4,
                    alphas = 1,
                    nfold = 1,
                    repl = 1)

lambdas <- seq(0, 0.5, by = 0.01)
enetLTS_list <- lapply(lambdas, FUN = function(x) enetLTS(xx = train1_dirty_X,
                                                          yy = train1_dirty_y,
                                                          family = "binomial",
                                                          lambdas = x,
                                                          alphas = 1,
                                                          nfold = 1,
                                                          repl = 1))

# Predicting
enetLTS_logit3_preds <- unname(unlist(predict(enetLTS_logit3,
                                              newX = test1_X,
                                              type = "response",
                                              vers = "reweighted")))
enetLTS_logit3b_preds <- unname(unlist(predict(enetLTS_logit3b,
                                              newX = test1_X,
                                              type = "response",
                                              vers = "reweighted")))
# Loss
logit_loss(y_true = test1_y, prob_hat = enetLTS_logit3_preds)
logit_loss(y_true = test1_y, prob_hat = enetLTS_logit3b_preds)

```

TO DO: complete the enetLTS_list: getting predictions for them all and checking the differences.


Related to the whole AIC/BIC issue. In the KHF paper, p. 11, top it says "Note that the evaluation criteria given by [the MNLL] are robust against outliers, because they are based on the best subsets of size h, which are supposed to be outlier free.
```{r}
model <- enetLTS_logit3


enetLTS_logit3$objective/enetLTS_logit3$h # This is the mean?
enetLTS_logit3$best
enetLTS_logit3$inputs

enetLTS_logit3$residuals[enetLTS_]


sum(model$residuals[model$best])
model$objective


-1 * enetLTS_logit3$residuals - 2/enetLTS_logit3$h * enetLTS_logit3$num.nonzerocoef

names()

model$objective # 9.27
model$residuals # "Deviance residuals", i.e. their sum is the deviance, REWEIGHTED
residuals(model) # Same as above (deviance residuals) (REWEIGHTED)

sum(model$raw.residuals) # Raw
sum(model$residuals) # Reweighted

# Do these become the same as the $objective
sum(model$residuals[model$best]) + model$h * model$lambdaw * sum(abs(model$coefficients))
sum((model$raw.residuals * model$raw.wt)[model$best]) + model$h * model$lambda * sum(abs(model$raw.coefficients))


length(model$residuals[model$best])

```
Note that the objective is, the __penalized__ sum of the __h__ deviances, from the __raw fits!__

Good question: what actually causes the difference between the raw fit and the reweighted one. My understanding: we can bypass it using the `del` option. And setting it to 0. 
```{r}
enetLTS_logit3c <- enetLTS(xx = train1_dirty_X,
                    yy = train1_dirty_y,
                    family = "binomial",
                    lambdas = 0.01,
                    alphas = 0.8,
                    nfold = 1,
                    repl = 1,
                    del = 0.4)
sum(enetLTS_logit3c$raw.residuals[enetLTS_logit3c$best])
sum(enetLTS_logit3c$residuals[enetLTS_logit3c$best])

```

Let's fit a simple enetLTS model for a binary regression problem and see what all the elements of the output are. For ease of notation we'll just call it `model`. We'll set alpha and lambda to a single value to get a LASSO model (alpha = 1) and allow for quick fitting.
```{r}
# Fitting
set.seed(1234)
model <- enetLTS(xx = train1_dirty_X,
                 yy = train1_dirty_y,
                 family = "binomial",
                 hsize =  0.75, # hsize = .75 default
                 lambdas = 0.01,
                 alphas = 1,
                 nfold = 1,
                 repl = 1)
# Looking at what's all in the model object
names(model) # 22 objects, let's take a look 1 by 1:

# Exploring all elements
model$objective # 12.00583
model$best
model$raw.wt
model$wt
model$a00
model$raw.coefficients # Does not include intercept but coef(model) DOES!
model$a0

```

The outputs of the enetLTS object:

* `$objective`: sum of the __h penalized__ deviances (see Â´$hsize` and `$``)
* `$best`: vector of length __h__ containing the observation indices of the observation in the best subset.  
* `$raw.wt`: binary vector of length __n__ that indicate the outliers from the raw fit
* `$wt`: binary vector of length __n__ that indicate the outliers from the reweighted fit. (to do: more info)
* `$a00`: intercept from the raw fit
* `$raw.coefficients`: 
* `$a0`: intercept from the reweighted fit

A bit of an unclear thing for me is: how does `$objective` relate to `$residuals` and loss in general? The explanation states that it's the sum of the $h$ (smallest?) deviances from the raw fits. We know we can access these raw deviance residuals through `$raw.residuals`. However these are of length $n$, hence we need to select the correct ones. Is this using `$best` or using `$wt`? We know `$objective` has a value of 12.00583, so we need to arrive to this number. Since we are penalizing the sum of the deviances with a positive quantity (l1 / l2 norm) we want the sum of these $h$ deviances to be __smaller__ than 12.00583! 

The penalty formulated is $\sum (1-\alpha) \frac{1}{2} \beta^2_j + \alpha |\beta_j|$ but it's not 100% clear if this includes the intercept or not. If, as is our case now, $\alpha = 1$, then this simplifies to $\sum |\beta_j|$. Hence the 
```{r}
# Quantity to arrive upon:
model$objective # 12.00583
# This should be the sum of the #h deviances that are PENALIZED

# Taking sums to see if we get close:
q1 <- sum(model$raw.residuals) # Sum of n deviances = 449.587
q2 <- sum(model$raw.residuals * model$raw.wt) # 13.61985 rather close but too big already
q3 <- sum(model$raw.residuals[model$best]) # 2.916376

# Calculating penalty
p1 <- sum(abs(model$raw.coefficients)) # 7.625889
p2 <- sum(abs(model$coefficients)) # 3.756319
p3 <- sum(abs(model$a00), abs(model$raw.coefficients)) # 7.689673
p4 <- sum(abs(model$a0), abs(model$coefficients)) # 3.7789
p5 <- sum(abs(coef(model))) # 3.7789

# Extracting h
h <- model$h

# Checking
q3 + h * model$lambda * p1
q3 + h * model$lambda * p2
q3 + h * model$lambda * p3
q3 + h * model$lambda * p4
q3 + h * model$lambda * p5


# Purely logically:
- train1_y[model$best] * 

model_preds <- unname(unlist(predict(model, newX = train1_dirty_X, vers = "reweighted", type = "response")))


lambda = 0.01


sum(logit_loss(y_true = train1_dirty_y[model$best], prob_hat = model_preds[model$best])$loss) + 0.01 * sum(abs(model$coefficients))

sum(-train1_dirty_y[model$best] * (train1_dirty_X[model$best, ] %*% model$coefficients) + log(1 + exp(train1_dirty_X[model$best, ] %*% model$coefficients))) + model$lambda * (sum(0.5 * (1 - model$alpha) * model$coefficients^2 + model$alpha * abs(model$coefficients)))

objective <- h * (mean((-yy[indexbest] * (xx[indexbest,] %*% coefficients)) +    # is it correct to use indexbest? should not we use raw.wt?
                                log(1+exp(xx[indexbest,] %*% coefficients))) +
                           lambdabest * sum(1/2 * (1-alphabest) * coefficients^2 +
                                               alphabest*abs(coefficients)))


X <- cbind(1, train1_dirty_X)
y <- train1_dirty_y
X_best <- X[model$best, ]
y_best <- y[model$best]
beta <- coef(model)
eta <- X_best %*% beta
h <- model$h
lambda <- model$lambda
alpha <- model$alpha


loss <- - y_best * eta + log(1 + exp(eta))
pen <- h * lambda * (sum(0.5 * (1 - alpha) * beta^2 + alpha * abs(beta)))
sum(loss) + pen # YES THIS IT IT!

loss == model$residuals[model$best] # Yes this is equal
loss == model$raw.residuals[model$best]





```

The AIC should go something like this:
```{r}
# AIC
-model$objective/model$h - 2 * length(coef(model) != 0)

# Going over some stuff
alphas <- c(0, runif(n = 18, min = 0, max = 1), 1)
lambdas <- c(0, runif(n = 50), min = 0, max = 1)

models <- enetLTS(xx = train1_dirty_X,
                  yy = train1_dirty_y,
                  family = "binomial",
                  alphas = alphas,
                  lambdas = lambdas,
                  repl = 1,
                  nfold = 10)
models$objective
#[1] "optimal model: lambda = 0.2158 alpha = 0.9608"



# Default setting BUT 1 repl for speed
model2 <- enetLTS(xx = train1_dirty_X,
                  yy = train1_dirty_y,
                  family = "binomial",
                  repl = 1,
                  nfold = 5)
# [1] "optimal model: lambda = 0.0066 alpha = 0.825"

model2$objective
length(model2$inputs$alphas)

model3 <- enetLTS(xx = train1_dirty_X,
                  yy = train1_dirty_y,
                  family = "binomial",
                  alphas = c(0, runif(n = 39, min = 0, max = 1), 1),
                  repl = 1,
                  nfold = 5)
model3$objective


model4 <- enetLTS(xx = train1_dirty_X,
                  yy = train1_dirty_y,
                  family = "binomial",
                  alphas = c(0, runif(n = 39, min = 0, max = 1), 1),
                  lambdas = c(0, runif(n = 40, min = 0, max = 1), 2:4),
                  repl = 1,
                  nfold = 5)
model4$objective








models <- lapply(lambdas, FUN = function(x) enetLTS(xx = train1_dirty_X,
                                                    yy = train1_dirty_y,
                                                    family = "binomial",
                                                    alphas = 1,
                                                    lambdas = x,
                                                    repl = 1,
                                                    nfold = 1))




```

```{r}
alphas <- seq(0, 1, by = 0.02)

model_list <- lapply(alphas, FUN = function(x) glmnet(x = train1_X,
                                                      y = train1_y,
                                                      family = "binomial",
                                                      alpha = x))

# Extracting lambda paths
lambda_path <- vector("list", length = length(alphas))
dfs <- vector("list", length = length(alphas))
for(i in 1:length(alphas)){
  lambda_path[[i]] <- model_list[[i]]$lambda
  dfs[[i]] <- model_list[[i]]$df
}

# Logliks
logitloss <- vector("list", length = length(alphas))
min_per_alpha <- matrix(NA, nrow = length(alphas), ncol = 4)
rownames(min_per_alpha) <- paste(alphas)
colnames(min_per_alpha) <- c("lambda", "avg_loss", "df", "AIC")
for(i in 1:length(alphas)){
  logitloss[[i]] <- matrix(NA, ncol = 4, nrow = length(lambda_path[[i]]))
  colnames(logitloss[[i]]) <- c("lambda", "loss", "df", "AIC")
  logitloss[[i]][, 1] <- lambda_path[[i]]
  logitloss[[i]][, 3] <- dfs[[i]]
  for(j in 1:length(lambda_path[[i]])){
    preds <- predict(model_list[[i]], newx = train1_X, s = lambda_path[[i]][j], type = "response")
    logitloss[[i]][j, 2] <- logit_loss(y_true = train1_y, prob_hat = preds)$avg_loss
  }
  min_loss_per_alpha <- min(logitloss[[i]][, 2])
  min_lambda_per_alpha <- logitloss[[i]][which.min(logitloss[[i]][, 2]), 1]
  min_per_alpha[i, 1] <- min_lambda_per_alpha
  min_per_alpha[i, 2] <- min_loss_per_alpha
}

n <- length(train1_y)

# AIC calc
for(i in 1:length(alphas)){
  logitloss[[i]][, 4] <- logitloss[[i]][, 2] - 2*logitloss[[i]][, 3]/n
}
```


# IDEAS:



```{r}

set.seed(1)
library("glmnet")
x <- matrix(rnorm(100*20),100,20)
y <- rnorm(100)

mysd <- function(y) sqrt(sum((y-mean(y))^2)/length(y))
sx <- scale(x, scale=apply(x, 2, mysd))
sx <- as.matrix(sx, ncol=20, nrow=100)

y_bin <- factor(ifelse(y<0, -1, 1))
prop.table(table(y_bin)) 
# y_bin
#   -1    1 
# 0.62 0.38 
fitGLM_log <- glmnet(sx, y_bin, family = "binomial")
max(fitGLM_log$lambda)
# [1] 0.1214006
max(abs(colSums(sx*ifelse(y<0, -.38, .62))))/100
# [1] 0.1214006
```

# Testing basis for AIC

Seeing if our changed code works for nfold = 1
```{r}
## Assigning our new code
# Sourcing
source(file = "C://Users/Vincent Wauters/Google Drive/Schoolwerk/KU Leuven/Thesis_Sparse_Robust_Logistic_Regression/enetLTS_UPDATED/cv.enetLTS_UPDATE.R")
# Assigning to namespace
assignInNamespace("cv.enetLTS", cv.enetLTS_UPDATE, "enetLTS")
#assignInNamespace("calc_evalCrit", calc_evalCrit_UPDATE, "enetLTS") # Doesn't seem to be necessary as it was defined within
assignInNamespace("enetLTS", enetLTS_UPDATE, "enetLTS") # doesnt work

# Running
enetLTS_logit1_temp <- enetLTS(xx = train1[, -1],
                    yy = train1[, 1],
                    family = "binomial",
                    nfold = 1,
                    repl = 1,
                    plot = FALSE) # plot = FALSE because still some problems with external functions (e.g. melt(), grid.newpage())

# Trying with plot = TRUE
enetLTS_logit1_temp <- enetLTS(xx = train1[, -1],
                    yy = train1[, 1],
                    family = "binomial",
                    nfold = 1,
                    repl = 1,
                    plot = TRUE)
```

Yes it works and it's quite fast! Only thing is the plotting function that has some trouble getting the melt(), grid.newpage(), pushViewport() functions to work, probably because it's coming from another package.

Let's now try to calculate the AIC for LASSO models, as the df calculation for the AIC is easy: just number of nonzero coefs.
```{r}
enetLTS_logit1_temp <- enetLTS:::enetLTS(xx = train1[, -1],
                               yy = train1[, 1],
                               family = "binomial",
                               alphas = 1, # LASSO,
                               nfold = 1,
                               repl = 1,
                               plot = TRUE,
                               ic_type = "AIC")
# OKAY WEIRD: it always selects a model with lambda = 0, so no regularization. Let's just run 3 models or so
lambdas <- c(0.0001, 0.01, 0.1, 0)
enetLTS_list_temp <- lapply(lambdas, FUN = function(x) enetLTS:::enetLTS(xx = train1[, -1],
                                                                         yy = train1[, 1],
                                                                         family = "binomial",
                                                                         alphas = 1, # LASSO,
                                                                         lambdas = x,
                                                                         lambdaw = x,
                                                                         del = 0,
                                                                         nfold = 1,
                                                                         repl = 1,
                                                                         plot = TRUE,
                                                                         ic_type = "AIC"))
for(i in 1:length(enetLTS_list_temp)){
  print(c(enetLTS_list_temp[[i]]$lambda, enetLTS_list_temp[[i]]$lambdaw))
  #print(enetLTS_list_temp[[i]]$lambdaw)
}
```


Let's see if AIC then works for setting del = 0. Again with alphas = 1, fixed for ease of computation of the degrees of freedom for the information criterion.
```{r}
set.seed(500)
enetLTS_logit1_temp <- enetLTS:::enetLTS(xx = train1[, -1],
                               yy = train1[, 1],
                               family = "binomial",
                               nfold = 1,
                               repl = 1,
                               plot = TRUE,
                               ic_type = "EBIC")
enetLTS_logit1_temp$num.nonzerocoef

set.seed(500)
enetLTS_logit2_temp <- enetLTS:::enetLTS(xx = train1[, -1],
                               yy = train1[, 1],
                               family = "binomial",
                               nfold = 1,
                               repl = 1,
                               plot = TRUE,
                               ic_type = "BIC")
enetLTS_logit2_temp$num.nonzerocoef

set.seed(500)
enetLTS_logit4_temp <- enetLTS:::enetLTS(xx = train1[, -1],
                               yy = train1[, 1],
                               family = "binomial",
                               nfold = 1,
                               repl = 1,
                               plot = TRUE,
                               ic_type = "AIC")
enetLTS_logit3_temp$num.nonzerocoef

# what about returning mulitple values
```
Gives kind of weird results, so let's now see if it actually maybe gives better results!

A lot of code from before is copied here. I adjusted the logit_sim function to also have a part for enetLTS_IC, i.e. enetLTS by IC selection.
```{r}
# Parameters
p_a <- 5
p_b <- 45
beta <- c(rep(1, times = p_a), rep(0, times = p_b))
p <- length(beta)
seed <- 596442 # KU Leuven student nr.
n <- 100
dirty <- 0.05
ic_type = "AIC"
runs <- 3


# Running simulation oevr different fitting types
types <- c("enetLTS_IC")
sim3 <- lapply(types, FUN = function(x) logit_sim(beta = beta, 
                         p = p,
                         p_a = p_a,
                         n = n,
                         runs = runs,
                         dirty = dirty,
                         dgp = "bernoulli",
                         type = x,
                         seed = seed,
                         ic_type = "AIC"))
names(sim3) <- c("enetLTS_IC1")

# Creating Summary
sim3_summary <- logit_sim_summary(sim3)

# Checking structure (names) of the sim1_summary
names(sim1_summary)

# Plotting some quantities
boxplot(sim3_summary$loss, main = "Test Loss")
boxplot(sim3_summary$misclass, main = "Misclassification Loss")
boxplot(sim3_summary$fpr, main = "Coefficient False Positive Rate")
boxplot(sim3_summary$tpr, main = "Coefficient True Positive Rate")
boxplot(sim3_summary$prec, main = "Coefficient Avg. RMSE")
```



# NOTE: how to edit nasty functions in packages:
```{r}
trace("enetLTS", edit=TRUE) # To get the edits
# Don't do any edit in the window
# make your own function by copying the original in an R file
assignInNamespace("enetLTS", enetLTS_UPDATE, "enetLTS")

# getting old function:
#assignInNamespace("enetLTS", enetLTS, "enetLTS")


# Also make sure all fucntions from the enetLTS package have enetLTS::: before them

## TO END:
untrace("enetLTS")
```


# ideas

WHAT ABOUT SOMEKIND OF AUC FOR BETA RECOVERY (is also 2 outcome thing) or confusion matrix
* We can do BIC approach by just setting
* Also reproduceability of logit_sim due to random element
* is the use of logistic loss still usefull when having fitted the model with penalization
* can we tune alpha?
* I think we might have some problems. Okay suppose we want to make use of the lambda warm starts in the glmnet fitting. Problem is, our h-subsets are also based on somekind of lambda-alpha values and they might not be the same as the ones that glmnet outputs...
* Lamba_max (0) calcualtion for logistic regression: it seems lambda_max for a logistic regression is calculated similarly, with weights based on class proportions:
* Change type.measure in the reweighting step to loglikelihood
* Tune for alpha at reweighting as well
* Gaussian process to estimate the error (tuning)

# NOTES

* The lognet() warning "one binomial calss has fewer than 8 observations, dangerous grounds comes from the warmCsteps()" function
* Is the intercept correctly left alone?